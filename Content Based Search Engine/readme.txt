Algorithms & Methods Involved:

Keypoints and descriptors extraction
	Fast Hessian keypoint detector algorithms
	Local scale-invariant feature descriptors (RootSIFT)

Feature storage and indexing
	Structure HDF5 dataset

Clustering features to generate a codebook
	K-means algorithms

Visualizing codeword entries (centroids of clustered features)

Vector quantization
	BOVW extraction
	BOVW storage and indexing

Inverted indexing
	Implement redis for inverted index

Search performing

Results:
	
1. Extract keypoints and descriptors

This is the step 1 in building the bag of visual word (BOVW).
In order to extract features from each image in the dataset, I use Fast Hessian method for keypoint detectors and use RootSIFT for local invariant descriptors.

--The descriptors/ directory (inside image_search_engine/image_search_pipeline/ directory) contains detectanddescribe.py, which implements to extract keypoints and local invariant descriptors from the dataset.

--The index/ directory inside image_search_engine/image_search_pipeline/ directory contains object-oriented interfaces to the HDF5 dataset to store features. In this part, baseindexer.py and featureindexer.py are used for storing features.


run : python index_features.py --dataset dat_a --features_db output/features.hdf5

2. Cluster features

This is the step 2 in building the bag of visual word (BOVW).

The next step is to cluster extracted feature vectors to form "vocabulary", or simply result the cluster centers generated by the K-means algorithm.

--The Vocabulary class inside vocabulary.py (check here) from information_retrieval/ directory (inside image_search_engine/image_search_pipeline/ directory) is used to ingest features.hdf5 dataset of features and then return cluster centers of visual words. These visual words will serve as our vector prototypes when I quantize the feature vectors into a single histogram of visual word occurrences in one of the following step.

The cluster_fetures.py is the driver script that clusters features.

--The MiniBatchKMeans is used, which is a more efficient and scalable version of the original k-means algorithm. It essentially works by breaking the dataset into small segments, clustering each of the segments individually, then merging the clusters resulting from each of these segments together to form the final solution. This is in stark contrast to the standard k-means algorithm which clusters all of the data in a single segment. While the clusters obtained from mini-batch k-means aren’t necessarily as accurate as the ones using the standard k-means algorithm, the primary benefit is that mini-batch k-means is that it’s often an order of magnitude (or more) faster than standard k-means.

run: python cluster_features.py --features_db output/features.hdf5 --codebook output/vocab.cpickle --clusters 1536 --percentage 0.25


3. Visualize features

The visualize_centers.py can help us to visualize the cluster centers from the codebook.

run : python visualize_centers.py --dataset dat_a --features_db output/features.hdf5 --codebook output/vocab.cpickle --output output/vw_vis

4. Vector quantization

The bagofvisualwords.py in information_retrieval/ directory (inside image_search_engine/image_search_pipeline/ directory) contains a BagOfVisualWords class that helps to extract BOVW histogram representations from each image in the dataset.

The bovwindexer.py in indexer/ directory contains a BOVWIndexer class to efficiently store BOVW histograms in an HDF5 dataset.

The extract_bovw.py is a driver file to handle looping over each of the images in features.hdf5 dataset, constructing a BOVW for the feature vectors associated with each image, and then adding them to the BOVWIndexer.

run : python extract_bovw.py --features_db output/features.hdf5 --codebook output/vocab.cpickle --bovw_db output/bovw.hdf5 --idf output/idf.cpickle

5. Inverted indexing

On another terminal run : redis-server

The redisqueue.py inside database/ directory (inside image_search_engine/image_search_pipeline/ directory) will be used to interface with redis data store.

The build_redis_index.py will take bovw.hdf5 dataset containing BOVW representations for each image in our dataset and build the inverted index inside redis.

run : python build_redis_index.py --bovw_db output/bovw.hdf5

6. Search performance

The searchresult.py inside information_retrieval/ directory defines a named tuple SearchResult, an object used to store:

--Our search results, or simply, the list of images that are similar to our query image.
--Any additional meta-data associated with the search, such as the time it took to perform the search.
--The dist.py (check here) inside information_retrieval/ directory defines a chi2_distance function to compute distance between two histograms.

The searcher.py inside information_retrieval/ directory defines a Searcher class that can:

--Use the inverted index to filter images that will have their chi-square distance explicitly computed by only grabbing image indexes that share a significant number of visual words with the query image.
--Compare BOVW histograms from the short list of image indexes using the chi-sqaure distance.
The search.py  is the driver script that is used to perform an actual search. It will be responsible for:

--Loading a query image.
--Detecting keypoints, extracting local invariant descriptors, and constructing a BOVW histogram.
--Querying the Searcher using the BOVW histogram.
--Displaying the output results to our screen.

run : python search.py --dataset dat_a --features_db output/features.hdf5 --bovw_db output/bovw.hdf5 --codebook output/vocab.cpickle --query dat_a/img175630.jpg